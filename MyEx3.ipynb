{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as spio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file, Platform: GLNXA64, Created on: Sun Oct 16 13:09:09 2011',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'X': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " 'y': array([[10],\n",
       "        [10],\n",
       "        [10],\n",
       "        ...,\n",
       "        [ 9],\n",
       "        [ 9],\n",
       "        [ 9]], dtype=uint8)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#导入matlab格式文件\n",
    "data =spio.loadmat('ex3data1.mat')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 400), (5000, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#可以看出data代表dict字典数据类型，字典是Python中唯一内建的映射类\n",
    "# X 和 y都是数组\n",
    "data['X'].shape, data['y'].shape#要同时显示，记得打逗号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试shape在数组和矩阵中区别\n",
    "#data['X'].shape[0]#5000  ,在数组中返回行\n",
    "#X_Matrix = np.matrix(data['X'])\n",
    "#X_Matrix.shape[0]#5000 也是返回行\n",
    "#len(X_Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#测试下sigmoid函数\n",
    "sigmoid(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#编写代价函数\n",
    "def cost(theta , X  ,y , learnRate):\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    theta = np.matrix(theta)\n",
    "    #记住在深度学习中一般字母表示都是列向量，但是在python中都是创建的行向量\n",
    "    first = np.multiply(y, np.log(sigmoid(X*theta.T)) )\n",
    "    second = np.multiply(1-y, np.log(1-sigmoid(X*theta.T)) )\n",
    "    reg = learnRate * np.sum(np.power(theta[: , 1: theta.shape[1] ] , 2  ))/(2*len(X))\n",
    "    return np.sum(-first - second)/len(X) +reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#梯度下降法就是来求使代价函数最小的theta取值\n",
    "#这是求梯度，不是梯度下降\n",
    "def grad(theta , X , y , learnRate):\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    theta = np.matrix(theta)\n",
    "    #判断有多少theta有多少个，也就是循环多少次\n",
    "    parameters = theta.shape[1]\n",
    "    #构建一个数组用来存储梯度\n",
    "    for j in range(parameters):\n",
    "        if j ==0:\n",
    "            grad[j] = np.sum( np.mulitiply( sigmid(X*theta.T) - y   , X[ : , j ] )) / len(X)\n",
    "        else:\n",
    "            #theta是一维数组，转换为行向量\n",
    "            grad[j] = np.sum( np.mulitiply( sigmid(X*theta.T) - y   , X[ : , j ] )) / len(X) +learnRate*theta[: , j]/len(X)\n",
    "    return grad;  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#测试 theta[j] 与 theta[; , j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#向量化\n",
    "def grad(theta , X , y , learnRate):#X是5000，401   ， y是5000 ， 1  ，theta是 1，401\n",
    "    X = np.matrix(X)#可以不用转矩阵，数组中一样可以运算。matrix可以用*来进行矩阵运算\n",
    "    y = np.matrix(y)\n",
    "    theta = np.matrix(theta)\n",
    "    parameters = theta.shape[1]\n",
    "    error = sigmoid(X*theta.T) - y #是一个(5000,1)的矩阵\n",
    "    #(X.T * error) 对应位置点乘然后按列相加  ,也就是X.T为 401，5000的矩阵，返回的是401，1的矩阵\n",
    "    #经过测试 np.mulitiply(errot , X)返回的是一个 5000，401的矩阵\n",
    "    grad =np.sum(np.multiply(error , X) , 0 ) /len(X) + learnRate*theta/len(X)# 测试返回1,401\n",
    "    return np.array(grad).ravel() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试 error = sigmid(X*theta.T)是数组还是列表，列表不具有数组的一些属性\n",
    "慢点想，追求懂，不追求进度\n",
    "仔细思考下向量化的含义\n",
    "结合下面表达式，可以看出来梯度，也就是后面不带a的部分， 有部分是不变的，类似于 \n",
    "A[x1 ,x2 ,... xj]+B[theta1,theta2...thetaj]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{align}\n",
    "  & Repeat\\text{ }until\\text{ }convergence\\text{ }\\!\\!\\{\\!\\!\\text{ } \\\\ \n",
    " & \\text{     }{{\\theta }_{0}}:={{\\theta }_{0}}-a\\frac{1}{m}\\sum\\limits_{i=1}^{m}{[{{h}_{\\theta }}\\left( {{x}^{(i)}} \\right)-{{y}^{(i)}}]x_{_{0}}^{(i)}} \\\\ \n",
    " & \\text{     }{{\\theta }_{j}}:={{\\theta }_{j}}-a\\frac{1}{m}\\sum\\limits_{i=1}^{m}{[{{h}_{\\theta }}\\left( {{x}^{(i)}} \\right)-{{y}^{(i)}}]x_{j}^{(i)}}+\\frac{\\lambda }{m}{{\\theta }_{j}} \\\\ \n",
    " & \\text{          }\\!\\!\\}\\!\\!\\text{ } \\\\ \n",
    " & Repeat \\\\ \n",
    "\\end{align}\n",
    "\n",
    "以下是原始代码是使用for循环的梯度函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        ...,\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#求证error\n",
    "x0=np.zeros(data['X'].shape[0])\n",
    "X = np.insert(data['X'] , 0 , values=x0 , axis = 1)\n",
    "X.shape\n",
    "theta = np.zeros(X.shape[1])\n",
    "X = np.matrix(X)\n",
    "theta = np.matrix(theta)\n",
    "sigmoid(X*theta.T)\n",
    "#经过测试sigmoid返回的是矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试np.insert插入多维数组\n",
    "x0 = np.zeros( (2, data['X'].shape[1] )  )\n",
    "x0\n",
    "X1 = np.insert(data['X'] , 0 , values=x0 , axis = 1)\n",
    "X1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y=data['y']\n",
    "error = sigmoid(X*theta.T) - y\n",
    "grad=np.sum(np.multiply(error , X) , 1)\n",
    "error.shape\n",
    "m=np.multiply(error , X)\n",
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def one_vs_all(X, y, num_labels, learning_rate):\n",
    "    rows = X.shape[0]\n",
    "    params = X.shape[1]\n",
    "    \n",
    "    # k X (n + 1) array for the parameters of each of the k classifiers\n",
    "    all_theta = np.zeros((num_labels, params + 1))#这个num labels？标签数\n",
    "    \n",
    "    # insert a column of ones at the beginning for the intercept term\n",
    "    X = np.insert(X, 0, values=np.ones(rows), axis=1)#添加x0=1\n",
    "    \n",
    "    # labels are 1-indexed instead of 0-indexed  在哪里避免混淆？识别0-9\n",
    "    for i in range(1, num_labels + 1):\n",
    "        theta = np.zeros(params + 1)\n",
    "        y_i = np.array([1 if label == i else 0 for label in y])\n",
    "        #搞清楚for in用法？上面是可迭代对象？读懂推导式？\n",
    "        y_i = np.reshape(y_i, (rows, 1))\n",
    "        \n",
    "        # minimize the objective function\n",
    "        fmin = minimize(fun=cost, x0=theta, args=(X, y_i, learning_rate), method='TNC', jac=gradient)\n",
    "        all_theta[i-1,:] = fmin.x\n",
    "    \n",
    "    return all_theta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
